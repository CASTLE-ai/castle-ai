{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = 'temp/'\n",
    "\n",
    "video_path = '../demo/case2-openfield/openfield-1min-raw.mp4'\n",
    "masks_path = f'{project_root}mask.mp4'\n",
    "\n",
    "video_align_path = f'{project_root}video-align.mp4'\n",
    "mask_align_path = f'{project_root}mask-align.mp4'\n",
    "\n",
    "body_rgb = [122, 228, 240]\n",
    "tail_rgb = [255, 208, 236]\n",
    "crf = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from castle.utils.video_io import ReadArray, WriteArray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = ReadArray(video_path)\n",
    "masks = ReadArray(masks_path)\n",
    "fps = video.fps\n",
    "video_align = WriteArray(video_align_path, fps, crf)\n",
    "masks_align = WriteArray(mask_align_path, fps, crf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 1800\n"
     ]
    }
   ],
   "source": [
    "print(len(video), len(masks))\n",
    "n = min(len(video), len(masks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roi_connected_components(frame, roi):\n",
    "    mask = np.zeros_like(frame[:, :, 0])\n",
    "    tolerance = 20\n",
    "    lower_bound = np.array([roi[0] - tolerance,\n",
    "                            roi[1] - tolerance,\n",
    "                            roi[2] - tolerance])\n",
    "    upper_bound = np.array([roi[0] + tolerance,\n",
    "                            roi[1] + tolerance,\n",
    "                            roi[2] + tolerance])\n",
    "    within_range = cv2.inRange(frame, lower_bound, upper_bound)\n",
    "    mask[within_range > 0] = 255\n",
    "    output = cv2.connectedComponentsWithStats(mask, 8, cv2.CV_32S)\n",
    "    num_labels = output[0]\n",
    "    if num_labels == 1:\n",
    "        return False, None\n",
    "    \n",
    "    return True, output\n",
    "\n",
    "\n",
    "\n",
    "def get_contour(frame, roi):\n",
    "    ok, connected_components = roi_connected_components(frame, roi)\n",
    "    if not ok:\n",
    "        return False, None\n",
    "    num_labels, labels, stats, centroids = connected_components\n",
    "    \n",
    "    areas = [stats[j, cv2.CC_STAT_AREA] for j in range(1, num_labels)]\n",
    "    maxi_comp_id = np.argmax(areas)\n",
    "    selected_label = (labels == (maxi_comp_id+1)).astype(np.uint8) * 255\n",
    "    _, binary_mask = cv2.threshold(selected_label, 0, 255, cv2.THRESH_BINARY)\n",
    "    contour = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[0][0]\n",
    "    contour = contour.squeeze()\n",
    "    if contour.ndim == 1:\n",
    "        return False, None\n",
    "    return True, contour\n",
    "    \n",
    "    \n",
    "def get_centroids(frame, roi):\n",
    "    ok, connected_components = roi_connected_components(frame, roi)\n",
    "    if not ok:\n",
    "        return False, None, None\n",
    "    num_labels, _, stats, centroids = connected_components\n",
    "    areas = [stats[i, cv2.CC_STAT_AREA] for i in range(1, num_labels)]\n",
    "    max_label = np.argmax(areas)\n",
    "    x = centroids[max_label + 1][0]\n",
    "    y = centroids[max_label + 1][1]\n",
    "    return True, x, y\n",
    "\n",
    "\n",
    "def get_mask(frame, roi):\n",
    "    ok, connected_components = roi_connected_components(frame, roi)\n",
    "    if not ok:\n",
    "        return False, None\n",
    "    num_labels, labels, stats, centroids = connected_components\n",
    "    areas = [stats[i, cv2.CC_STAT_AREA] for i in range(1, num_labels)]\n",
    "    max_label = np.argmax(areas)\n",
    "    return True,  (labels == (max_label+1))\n",
    "    \n",
    "    \n",
    "def find_closest_points(ref, contour):\n",
    "    mini = int(1e6)\n",
    "    point_close = None\n",
    "\n",
    "    for i in range(len(contour)):\n",
    "        distance = cv2.norm(ref - contour[i])\n",
    "        if distance < mini:\n",
    "            mini = distance\n",
    "            point_close = contour[i]\n",
    "\n",
    "    return point_close, mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 1476/1800 [00:31<00:06, 51.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No mask at the frame id = 1470. And skip it.\n",
      "No mask at the frame id = 1471. And skip it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1800/1800 [00:38<00:00, 46.47it/s]\n"
     ]
    }
   ],
   "source": [
    "thetas = []\n",
    "\n",
    "crop_h, crop_w = 640, 640\n",
    "raw_h, raw_w = video[0].shape[:2]\n",
    "u, d = int(raw_h // 2 - crop_h // 2), int(raw_h // 2 + crop_h // 2)\n",
    "l, r = int(raw_w // 2 - crop_w // 2), int(raw_w // 2 + crop_w // 2)\n",
    "center = (raw_w // 2, raw_h // 2)\n",
    "\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "\n",
    "    m = masks[i]\n",
    "    ok, body_x, body_y = get_centroids(m, body_rgb)\n",
    "    if not ok:\n",
    "        print(f'No mask at the frame id = {i}. And skip it.')\n",
    "        continue\n",
    "    ok, tail_contour = get_contour(m, tail_rgb)\n",
    "    if not ok:\n",
    "        print(f'No mask at the frame id = {i}. And skip it.')\n",
    "        continue\n",
    "    (tail_root_x, tail_root_y), _ = find_closest_points((body_x, body_y), tail_contour)\n",
    "    theta = np.arctan2(tail_root_y - body_y, tail_root_x - body_x) * 180 / np.pi\n",
    "    thetas.append(theta)\n",
    "    \n",
    "    f = video[i]\n",
    "    matrix = np.float32([[1, 0, center[0] - body_x], [0, 1, center[1] - body_y]])\n",
    "    f = cv2.warpAffine(f, matrix, (raw_w, raw_h))\n",
    "    m = cv2.warpAffine(m, matrix, (raw_w, raw_h))\n",
    "    matrix = cv2.getRotationMatrix2D(center, theta-90, 1.0)\n",
    "    f = cv2.warpAffine(f, matrix, (raw_w, raw_h))\n",
    "    m = cv2.warpAffine(m, matrix, (raw_w, raw_h))\n",
    "    f = f[u:d, l:r]\n",
    "    m = m[u:d, l:r]\n",
    "    video_align.append(f)\n",
    "    masks_align.append(m)\n",
    "\n",
    "\n",
    "masks_align.close()    \n",
    "video_align.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
